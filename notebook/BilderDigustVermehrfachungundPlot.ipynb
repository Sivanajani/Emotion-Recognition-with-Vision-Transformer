{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Pfad \n",
    "folder = 'EmotionenDisgustAngepasst/train/disgusted'\n",
    "\n",
    "# Bilder horizontal geflippt\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(('.jpg', '.png')):\n",
    "        img = Image.open(os.path.join(folder, file))\n",
    "        flipped_img = F.hflip(img)\n",
    "        flipped_img.save(os.path.join(folder, f\"Hflipped_{file}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Pfad \n",
    "folder = 'EmotionenDisgustAngepasst/train/disgusted'\n",
    "\n",
    "# Bilder vertikal geflippt \n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(('.jpg', '.png')):\n",
    "        img = Image.open(os.path.join(folder, file))\n",
    "        flipped_img = F.vflip(img)\n",
    "        flipped_img.save(os.path.join(folder, f\"Vflipped_{file}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Pfad \n",
    "folder = 'EmotionenDisgustAngepasst/train/disgusted'\n",
    "\n",
    "# Bilder um 45 Grad rotiert\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(('.jpg', '.png')):\n",
    "        img = Image.open(os.path.join(folder, file))\n",
    "        rotated_img = F.rotate(img, angle=45)  # Rotiert um 45 Grad\n",
    "        rotated_img.save(os.path.join(folder, f\"45rotated_{file}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ordnerpfad und Suchmuster\n",
    "folder = 'EmotionenDisgustAngepasst/train/disgusted'\n",
    "pattern = 'im0.png'\n",
    "\n",
    "# Alle Bilder laden, die auf \"im0.png\" enden\n",
    "images = [Image.open(os.path.join(folder, file)) for file in os.listdir(folder) if file.endswith(pattern)]\n",
    "\n",
    "# Anzahl der Bilder für die Plot-Größe berechnen\n",
    "n = len(images)\n",
    "cols = 4  # Anzahl der Spalten\n",
    "rows = (n + cols - 1) // cols  # Zeilen so berechnen, dass alle Bilder passen\n",
    "\n",
    "# Figure erstellen und Bilder in Graustufen einfügen\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 3 * rows))\n",
    "for i, img in enumerate(images):\n",
    "    ax = axes[i // cols, i % cols]\n",
    "    ax.imshow(img, cmap=\"gray\")  # Graustufen-Farbkarte\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Leere Achsen entfernen (falls Bilder nicht in alle Felder passen)\n",
    "for j in range(i + 1, rows * cols):\n",
    "    fig.delaxes(axes[j // cols, j % cols])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_image_distribution():\n",
    "    # Get counts\n",
    "    data = {'test': {}, 'train': {}}\n",
    "    base_path = 'Emotionen'\n",
    "    \n",
    "    for split in ['test', 'train']:\n",
    "        split_path = os.path.join(base_path, split)\n",
    "        for emotion in os.listdir(split_path):\n",
    "            emotion_path = os.path.join(split_path, emotion)\n",
    "            if os.path.isdir(emotion_path):\n",
    "                data[split][emotion] = len([f for f in os.listdir(emotion_path) if f.endswith('.png')])\n",
    "    \n",
    "    # Plotting\n",
    "    labels = list(data['test'].keys())\n",
    "    test_counts = [data['test'][label] for label in labels]\n",
    "    train_counts = [data['train'][label] for label in labels]\n",
    "    \n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    rects1 = ax.bar(x - width/2, test_counts, width, label='Test')\n",
    "    rects2 = ax.bar(x + width/2, train_counts, width, label='Train')\n",
    "    \n",
    "    ax.set_ylabel('Number of Images')\n",
    "    ax.set_title('Image Distribution by Emotion Category')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate(f'{int(height)}',\n",
    "                       xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom')\n",
    "    \n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_image_distribution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_image_distribution():\n",
    "    base_path = 'Emotionen'\n",
    "    data = {\n",
    "        split: {\n",
    "            emotion: len(os.listdir(os.path.join(base_path, split, emotion))) \n",
    "            for emotion in os.listdir(os.path.join(base_path, split)) \n",
    "            if os.path.isdir(os.path.join(base_path, split, emotion))\n",
    "        } \n",
    "        for split in ['test', 'train']\n",
    "    }\n",
    "    sns.set_context('poster')\n",
    "    labels = data['test'].keys()\n",
    "    test_counts = list(data['test'].values())\n",
    "    train_counts = list(data['train'].values())\n",
    "    x = np.arange(len(labels))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 10))\n",
    "    ax.bar(x - 0.2, test_counts, 0.4, label='Test')\n",
    "    ax.bar(x + 0.2, train_counts, 0.4, label='Train')\n",
    "    \n",
    "    ax.set_ylabel('Anzahl Bilder')\n",
    "    ax.set_title('Bildverteiilung pro Emotion (Vor Anpassung)')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    \n",
    "    for counts, pos in zip([test_counts, train_counts], [x - 0.2, x + 0.2]):\n",
    "        [ax.text(p, c + 3, str(c), ha='center') for p, c in zip(pos, counts)]\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_image_distribution()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
